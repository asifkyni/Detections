{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "630a4d07-6318-47cd-9d96-75568e8d385e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 94\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Define loss function and optimizers\u001b[39;00m\n\u001b[1;32m     93\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[0;32m---> 94\u001b[0m optimizer_unet \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43munet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m optimizer_fpn \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(fpn\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     96\u001b[0m optimizer_siamese \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(siamese_net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/torch/optim/adam.py:45\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39mbetas, eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m     42\u001b[0m                 weight_decay\u001b[38;5;241m=\u001b[39mweight_decay, amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m     43\u001b[0m                 maximize\u001b[38;5;241m=\u001b[39mmaximize, foreach\u001b[38;5;241m=\u001b[39mforeach, capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m     44\u001b[0m                 differentiable\u001b[38;5;241m=\u001b[39mdifferentiable, fused\u001b[38;5;241m=\u001b[39mfused)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/torch/optim/optimizer.py:279\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    277\u001b[0m param_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(params)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer got an empty parameter list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param_groups[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    281\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n",
      "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score\n",
    "\n",
    "# Define U-Net Model\n",
    "class UNet(nn.Module):\n",
    "    # Define the U-Net architecture here\n",
    "    # For brevity, this is a placeholder\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        # Define layers here\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Forward pass implementation here\n",
    "        return x\n",
    "\n",
    "# Define FPN Model\n",
    "class FPN(nn.Module):\n",
    "    # Define the FPN architecture here\n",
    "    # For brevity, this is a placeholder\n",
    "    def __init__(self):\n",
    "        super(FPN, self).__init__()\n",
    "        # Define layers here\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Forward pass implementation here\n",
    "        return x\n",
    "\n",
    "# Define Siamese Network Model\n",
    "class SiameseNetwork(nn.Module):\n",
    "    # Define the Siamese Network architecture here\n",
    "    # For brevity, this is a placeholder\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        # Define layers here\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        # Forward pass implementation here\n",
    "        return x1, x2\n",
    "\n",
    "# Define ResNet-based Model\n",
    "class ResNetChangeDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetChangeDetector, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 2)  # Adjust output layer for change detection\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Dataset loading and preprocessing\n",
    "class ChangeDetectionDataset(Dataset):\n",
    "    def __init__(self, image_paths, label_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx])\n",
    "        label = Image.open(self.label_paths[idx])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            label = self.transform(label)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = ChangeDetectionDataset(image_paths=['path/to/images'], label_paths=['path/to/labels'], transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Initialize models\n",
    "unet = UNet()\n",
    "fpn = FPN()\n",
    "siamese_net = SiameseNetwork()\n",
    "resnet = ResNetChangeDetector()\n",
    "\n",
    "# Define loss function and optimizers\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_unet = optim.Adam(unet.parameters(), lr=1e-4)\n",
    "optimizer_fpn = optim.Adam(fpn.parameters(), lr=1e-4)\n",
    "optimizer_siamese = optim.Adam(siamese_net.parameters(), lr=1e-4)\n",
    "optimizer_resnet = optim.Adam(resnet.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop (for one epoch as an example)\n",
    "def train_model(model, optimizer, criterion, dataloader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    return running_loss / len(dataloader.dataset)\n",
    "\n",
    "# Training the models\n",
    "loss_unet = train_model(unet, optimizer_unet, criterion, train_loader)\n",
    "loss_fpn = train_model(fpn, optimizer_fpn, criterion, train_loader)\n",
    "loss_siamese = train_model(siamese_net, optimizer_siamese, criterion, train_loader)\n",
    "loss_resnet = train_model(resnet, optimizer_resnet, criterion, train_loader)\n",
    "\n",
    "print(f'UNet Loss: {loss_unet:.4f}')\n",
    "print(f'FPN Loss: {loss_fpn:.4f}')\n",
    "print(f'Siamese Network Loss: {loss_siamese:.4f}')\n",
    "print(f'ResNet Loss: {loss_resnet:.4f}')\n",
    "\n",
    "# Evaluation and Metrics\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            y_true.extend(labels.flatten())\n",
    "            y_pred.extend(preds.flatten())\n",
    "    return precision_score(y_true, y_pred), recall_score(y_true, y_pred), f1_score(y_true, y_pred), jaccard_score(y_true, y_pred)\n",
    "\n",
    "# Evaluate the models\n",
    "precision_unet, recall_unet, f1_unet, iou_unet = evaluate_model(unet, train_loader)\n",
    "precision_fpn, recall_fpn, f1_fpn, iou_fpn = evaluate_model(fpn, train_loader)\n",
    "precision_siamese, recall_siamese, f1_siamese, iou_siamese = evaluate_model(siamese_net, train_loader)\n",
    "precision_resnet, recall_resnet, f1_resnet, iou_resnet = evaluate_model(resnet, train_loader)\n",
    "\n",
    "print(f'UNet Precision: {precision_unet:.4f}, Recall: {recall_unet:.4f}, F1: {f1_unet:.4f}, IoU: {iou_unet:.4f}')\n",
    "print(f'FPN Precision: {precision_fpn:.4f}, Recall: {recall_fpn:.4f}, F1: {f1_fpn:.4f}, IoU: {iou_fpn:.4f}')\n",
    "print(f'Siamese Network Precision: {precision_siamese:.4f}, Recall: {recall_siamese:.4f}, F1: {f1_siamese:.4f}, IoU: {iou_siamese:.4f}')\n",
    "print(f'ResNet Precision: {precision_resnet:.4f}, Recall: {recall_resnet:.4f}, F1: {f1_resnet:.4f}, IoU: {iou_resnet:.4f}')\n",
    "\n",
    "# Visualization\n",
    "def visualize_results(images, labels, preds):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(3, len(images), i + 1)\n",
    "        plt.imshow(images[i].permute(1, 2, 0))\n",
    "        plt.title('Input Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(3, len(images), len(images) + i + 1)\n",
    "        plt.imshow(labels[i].squeeze(), cmap='gray')\n",
    "        plt.title('Ground Truth')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(3, len(images), 2 * len(images) + i + 1)\n",
    "        plt.imshow(preds[i].squeeze(), cmap='gray')\n",
    "        plt.title('Prediction')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Visualize results for a few examples\n",
    "images, labels = next(iter(train_loader))\n",
    "preds_unet = torch.sigmoid(unet(images)).cpu().numpy()\n",
    "preds_fpn = torch.sigmoid(fpn(images)).cpu().numpy()\n",
    "preds_siamese = torch.sigmoid(siamese_net(images, images)).cpu().numpy()\n",
    "preds_resnet = torch.sigmoid(resnet(images)).cpu().numpy()\n",
    "\n",
    "visualize_results(images, labels, preds_unet)\n",
    "visualize_results(images, labels, preds_fpn)\n",
    "visualize_results(images, labels, preds_siamese)\n",
    "visualize_results(images, labels, preds_resnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1679d8ed-7321-4b73-a856-14b833bce30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score\n",
    "\n",
    "# Define U-Net Model\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=2, stride=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Define FPN Model\n",
    "class FPN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FPN, self).__init__()\n",
    "        self.backbone = models.resnet50(pretrained=True)\n",
    "        self.backbone.fc = nn.Identity()  # Remove the classification layer\n",
    "        self.lateral = nn.Conv2d(2048, 256, kernel_size=1)\n",
    "        self.smooth = nn.Conv2d(256, 1, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.lateral(x)\n",
    "        x = self.smooth(x)\n",
    "        return x\n",
    "\n",
    "# Define Siamese Network Model\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128*53*53, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "    \n",
    "    def forward_one(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        output1 = self.forward_one(x1)\n",
    "        output2 = self.forward_one(x2)\n",
    "        return output1, output2\n",
    "\n",
    "# Define ResNet-based Model\n",
    "class ResNetChangeDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetChangeDetector, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 1)  # Adjust output layer for change detection\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Dataset loading and preprocessing\n",
    "class ChangeDetectionDataset(Dataset):\n",
    "    def __init__(self, image_paths, label_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx])\n",
    "        label = Image.open(self.label_paths[idx])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            label = self.transform(label)\n",
    "        \n",
    "        return image, l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff260fd-c690-4454-96e4-43e321d32c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
